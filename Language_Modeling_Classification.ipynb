{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf26d4f0-a929-4918-a557-7f270e827b81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T01:46:14.609242Z",
     "start_time": "2024-05-20T01:46:14.359444Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/marouandgh/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/marouandgh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/marouandgh/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a71c4a6b-9567-44a2-b1d5-ec071399db2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T01:46:15.252265Z",
     "start_time": "2024-05-20T01:46:14.590779Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  sentiment                                      Tweet Content\n0  Positive  im getting on borderlands and i will murder yo...\n1  Positive  I am coming to the borders and I will kill you...\n2  Positive  im getting on borderlands and i will kill you ...\n3  Positive  im coming on borderlands and i will murder you...\n4  Positive  im getting on borderlands 2 and i will murder ...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentiment</th>\n      <th>Tweet Content</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Positive</td>\n      <td>im getting on borderlands and i will murder yo...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Positive</td>\n      <td>I am coming to the borders and I will kill you...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Positive</td>\n      <td>im getting on borderlands and i will kill you ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Positive</td>\n      <td>im coming on borderlands and i will murder you...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Positive</td>\n      <td>im getting on borderlands 2 and i will murder ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"./twitter_training.csv\", names=[\"id\", \"entity\", \"sentiment\", \"Tweet Content\"])\n",
    "dataset = dataset.drop([\"id\", \"entity\"], axis=1)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42089211-71ed-4773-8c94-36f82dfc3fec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T01:46:15.356520Z",
     "start_time": "2024-05-20T01:46:15.201772Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 3 ... 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "labelencoder.fit(dataset[\"sentiment\"])\n",
    "\n",
    "labels = labelencoder.transform(dataset[\"sentiment\"])\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968962dc-75af-4da6-8bf0-a7aebcb966cb",
   "metadata": {},
   "source": [
    "# 1. NLP Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a921a28b-2469-4e16-9230-9abb6fc16758",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T01:46:31.896483Z",
     "start_time": "2024-05-20T01:46:15.253416Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      sentiment                                      Tweet Content  \\\n0      Positive  im getting on borderlands and i will murder yo...   \n1      Positive  I am coming to the borders and I will kill you...   \n2      Positive  im getting on borderlands and i will kill you ...   \n3      Positive  im coming on borderlands and i will murder you...   \n4      Positive  im getting on borderlands 2 and i will murder ...   \n...         ...                                                ...   \n74677  Positive  Just realized that the Windows partition of my...   \n74678  Positive  Just realized that my Mac window partition is ...   \n74679  Positive  Just realized the windows partition of my Mac ...   \n74680  Positive  Just realized between the windows partition of...   \n74681  Positive  Just like the windows partition of my Mac is l...   \n\n                                                  tokens  \n0      [im, getting, on, borderlands, and, i, will, m...  \n1      [i, am, coming, to, the, borders, and, i, will...  \n2      [im, getting, on, borderlands, and, i, will, k...  \n3      [im, coming, on, borderlands, and, i, will, mu...  \n4      [im, getting, on, borderlands, and, i, will, m...  \n...                                                  ...  \n74677  [just, realized, that, the, windows, partition...  \n74678  [just, realized, that, my, mac, window, partit...  \n74679  [just, realized, the, windows, partition, of, ...  \n74680  [just, realized, between, the, windows, partit...  \n74681  [just, like, the, windows, partition, of, my, ...  \n\n[74682 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentiment</th>\n      <th>Tweet Content</th>\n      <th>tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Positive</td>\n      <td>im getting on borderlands and i will murder yo...</td>\n      <td>[im, getting, on, borderlands, and, i, will, m...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Positive</td>\n      <td>I am coming to the borders and I will kill you...</td>\n      <td>[i, am, coming, to, the, borders, and, i, will...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Positive</td>\n      <td>im getting on borderlands and i will kill you ...</td>\n      <td>[im, getting, on, borderlands, and, i, will, k...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Positive</td>\n      <td>im coming on borderlands and i will murder you...</td>\n      <td>[im, coming, on, borderlands, and, i, will, mu...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Positive</td>\n      <td>im getting on borderlands 2 and i will murder ...</td>\n      <td>[im, getting, on, borderlands, and, i, will, m...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>74677</th>\n      <td>Positive</td>\n      <td>Just realized that the Windows partition of my...</td>\n      <td>[just, realized, that, the, windows, partition...</td>\n    </tr>\n    <tr>\n      <th>74678</th>\n      <td>Positive</td>\n      <td>Just realized that my Mac window partition is ...</td>\n      <td>[just, realized, that, my, mac, window, partit...</td>\n    </tr>\n    <tr>\n      <th>74679</th>\n      <td>Positive</td>\n      <td>Just realized the windows partition of my Mac ...</td>\n      <td>[just, realized, the, windows, partition, of, ...</td>\n    </tr>\n    <tr>\n      <th>74680</th>\n      <td>Positive</td>\n      <td>Just realized between the windows partition of...</td>\n      <td>[just, realized, between, the, windows, partit...</td>\n    </tr>\n    <tr>\n      <th>74681</th>\n      <td>Positive</td>\n      <td>Just like the windows partition of my Mac is l...</td>\n      <td>[just, like, the, windows, partition, of, my, ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>74682 rows Ã— 3 columns</p>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_tweet(text):\n",
    "    if not isinstance(text, str):\n",
    "        return ''\n",
    "    # Apply regular expression to replace non-alphabetical characters with a space\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    return cleaned_text\n",
    "\n",
    "# text Cleanign \n",
    "dataset[\"tokens\"] = dataset[\"Tweet Content\"].apply(lambda x: word_tokenize(clean_tweet(x).lower()))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f18b5946-82f4-40cd-ae2c-bea040871ee9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T01:46:32.820743Z",
     "start_time": "2024-05-20T01:46:31.885867Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      sentiment                                      Tweet Content  \\\n0      Positive  im getting on borderlands and i will murder yo...   \n1      Positive  I am coming to the borders and I will kill you...   \n2      Positive  im getting on borderlands and i will kill you ...   \n3      Positive  im coming on borderlands and i will murder you...   \n4      Positive  im getting on borderlands 2 and i will murder ...   \n...         ...                                                ...   \n74677  Positive  Just realized that the Windows partition of my...   \n74678  Positive  Just realized that my Mac window partition is ...   \n74679  Positive  Just realized the windows partition of my Mac ...   \n74680  Positive  Just realized between the windows partition of...   \n74681  Positive  Just like the windows partition of my Mac is l...   \n\n                                                  tokens  \n0                     [im, getting, borderlands, murder]  \n1                                [coming, borders, kill]  \n2                       [im, getting, borderlands, kill]  \n3                      [im, coming, borderlands, murder]  \n4                     [im, getting, borderlands, murder]  \n...                                                  ...  \n74677  [realized, windows, partition, mac, like, year...  \n74678  [realized, mac, window, partition, years, behi...  \n74679  [realized, windows, partition, mac, years, beh...  \n74680  [realized, windows, partition, mac, like, year...  \n74681  [like, windows, partition, mac, like, years, b...  \n\n[74682 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentiment</th>\n      <th>Tweet Content</th>\n      <th>tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Positive</td>\n      <td>im getting on borderlands and i will murder yo...</td>\n      <td>[im, getting, borderlands, murder]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Positive</td>\n      <td>I am coming to the borders and I will kill you...</td>\n      <td>[coming, borders, kill]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Positive</td>\n      <td>im getting on borderlands and i will kill you ...</td>\n      <td>[im, getting, borderlands, kill]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Positive</td>\n      <td>im coming on borderlands and i will murder you...</td>\n      <td>[im, coming, borderlands, murder]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Positive</td>\n      <td>im getting on borderlands 2 and i will murder ...</td>\n      <td>[im, getting, borderlands, murder]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>74677</th>\n      <td>Positive</td>\n      <td>Just realized that the Windows partition of my...</td>\n      <td>[realized, windows, partition, mac, like, year...</td>\n    </tr>\n    <tr>\n      <th>74678</th>\n      <td>Positive</td>\n      <td>Just realized that my Mac window partition is ...</td>\n      <td>[realized, mac, window, partition, years, behi...</td>\n    </tr>\n    <tr>\n      <th>74679</th>\n      <td>Positive</td>\n      <td>Just realized the windows partition of my Mac ...</td>\n      <td>[realized, windows, partition, mac, years, beh...</td>\n    </tr>\n    <tr>\n      <th>74680</th>\n      <td>Positive</td>\n      <td>Just realized between the windows partition of...</td>\n      <td>[realized, windows, partition, mac, like, year...</td>\n    </tr>\n    <tr>\n      <th>74681</th>\n      <td>Positive</td>\n      <td>Just like the windows partition of my Mac is l...</td>\n      <td>[like, windows, partition, mac, like, years, b...</td>\n    </tr>\n  </tbody>\n</table>\n<p>74682 rows Ã— 3 columns</p>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Removing StopWords\n",
    "dataset[\"tokens\"] = dataset[\"tokens\"].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce1c8cb7-bb58-45ce-a0ac-e56c7ab6ce76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T01:46:37.803369Z",
     "start_time": "2024-05-20T01:46:32.803631Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      sentiment                                      Tweet Content  \\\n0      Positive  im getting on borderlands and i will murder yo...   \n1      Positive  I am coming to the borders and I will kill you...   \n2      Positive  im getting on borderlands and i will kill you ...   \n3      Positive  im coming on borderlands and i will murder you...   \n4      Positive  im getting on borderlands 2 and i will murder ...   \n...         ...                                                ...   \n74677  Positive  Just realized that the Windows partition of my...   \n74678  Positive  Just realized that my Mac window partition is ...   \n74679  Positive  Just realized the windows partition of my Mac ...   \n74680  Positive  Just realized between the windows partition of...   \n74681  Positive  Just like the windows partition of my Mac is l...   \n\n                                                  tokens  \n0                      [im, getting, borderland, murder]  \n1                                 [coming, border, kill]  \n2                        [im, getting, borderland, kill]  \n3                       [im, coming, borderland, murder]  \n4                      [im, getting, borderland, murder]  \n...                                                  ...  \n74677  [realized, window, partition, mac, like, year,...  \n74678  [realized, mac, window, partition, year, behin...  \n74679  [realized, window, partition, mac, year, behin...  \n74680  [realized, window, partition, mac, like, year,...  \n74681  [like, window, partition, mac, like, year, beh...  \n\n[74682 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentiment</th>\n      <th>Tweet Content</th>\n      <th>tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Positive</td>\n      <td>im getting on borderlands and i will murder yo...</td>\n      <td>[im, getting, borderland, murder]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Positive</td>\n      <td>I am coming to the borders and I will kill you...</td>\n      <td>[coming, border, kill]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Positive</td>\n      <td>im getting on borderlands and i will kill you ...</td>\n      <td>[im, getting, borderland, kill]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Positive</td>\n      <td>im coming on borderlands and i will murder you...</td>\n      <td>[im, coming, borderland, murder]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Positive</td>\n      <td>im getting on borderlands 2 and i will murder ...</td>\n      <td>[im, getting, borderland, murder]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>74677</th>\n      <td>Positive</td>\n      <td>Just realized that the Windows partition of my...</td>\n      <td>[realized, window, partition, mac, like, year,...</td>\n    </tr>\n    <tr>\n      <th>74678</th>\n      <td>Positive</td>\n      <td>Just realized that my Mac window partition is ...</td>\n      <td>[realized, mac, window, partition, year, behin...</td>\n    </tr>\n    <tr>\n      <th>74679</th>\n      <td>Positive</td>\n      <td>Just realized the windows partition of my Mac ...</td>\n      <td>[realized, window, partition, mac, year, behin...</td>\n    </tr>\n    <tr>\n      <th>74680</th>\n      <td>Positive</td>\n      <td>Just realized between the windows partition of...</td>\n      <td>[realized, window, partition, mac, like, year,...</td>\n    </tr>\n    <tr>\n      <th>74681</th>\n      <td>Positive</td>\n      <td>Just like the windows partition of my Mac is l...</td>\n      <td>[like, window, partition, mac, like, year, beh...</td>\n    </tr>\n  </tbody>\n</table>\n<p>74682 rows Ã— 3 columns</p>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "dataset[\"tokens\"] = dataset[\"tokens\"].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4561e10b-04ad-42af-b36c-5aec3fdc09e1",
   "metadata": {},
   "source": [
    "# Word2Vec (CBOW and Skip-gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24e972bd-a1ce-4089-964c-e57fb3357521",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T01:46:37.995426Z",
     "start_time": "2024-05-20T01:46:37.801050Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'triu' from 'scipy.linalg' (/Users/marouandgh/Documents/IASD/NLP/Les Ateliers/Atelier_3/NLP_LAB_3/.venv/lib/python3.11/site-packages/scipy/linalg/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[25], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgensim\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Word2Vec\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnltk\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtokenize\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m word_tokenize\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Train Word2Vec models (CBOW and Skip-gram)\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/IASD/NLP/Les Ateliers/Atelier_3/NLP_LAB_3/.venv/lib/python3.11/site-packages/gensim/__init__.py:11\u001B[0m\n\u001B[1;32m      7\u001B[0m __version__ \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m4.3.2\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mlogging\u001B[39;00m\n\u001B[0;32m---> 11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgensim\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m parsing, corpora, matutils, interfaces, models, similarities, utils  \u001B[38;5;66;03m# noqa:F401\u001B[39;00m\n\u001B[1;32m     14\u001B[0m logger \u001B[38;5;241m=\u001B[39m logging\u001B[38;5;241m.\u001B[39mgetLogger(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgensim\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m logger\u001B[38;5;241m.\u001B[39mhandlers:  \u001B[38;5;66;03m# To ensure reload() doesn't add another one\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/IASD/NLP/Les Ateliers/Atelier_3/NLP_LAB_3/.venv/lib/python3.11/site-packages/gensim/corpora/__init__.py:6\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;124;03mThis package contains implementations of various streaming corpus I/O format.\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# bring corpus classes directly into package namespace, to save some typing\u001B[39;00m\n\u001B[0;32m----> 6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mindexedcorpus\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m IndexedCorpus  \u001B[38;5;66;03m# noqa:F401 must appear before the other classes\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmmcorpus\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m MmCorpus  \u001B[38;5;66;03m# noqa:F401\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbleicorpus\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BleiCorpus  \u001B[38;5;66;03m# noqa:F401\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/IASD/NLP/Les Ateliers/Atelier_3/NLP_LAB_3/.venv/lib/python3.11/site-packages/gensim/corpora/indexedcorpus.py:14\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mlogging\u001B[39;00m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m\n\u001B[0;32m---> 14\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgensim\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m interfaces, utils\n\u001B[1;32m     16\u001B[0m logger \u001B[38;5;241m=\u001B[39m logging\u001B[38;5;241m.\u001B[39mgetLogger(\u001B[38;5;18m__name__\u001B[39m)\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mIndexedCorpus\u001B[39;00m(interfaces\u001B[38;5;241m.\u001B[39mCorpusABC):\n",
      "File \u001B[0;32m~/Documents/IASD/NLP/Les Ateliers/Atelier_3/NLP_LAB_3/.venv/lib/python3.11/site-packages/gensim/interfaces.py:19\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;124;03m\"\"\"Basic interfaces used across the whole Gensim package.\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \n\u001B[1;32m      9\u001B[0m \u001B[38;5;124;03mThese interfaces are used for building corpora, model transformation and similarity queries.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     14\u001B[0m \n\u001B[1;32m     15\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mlogging\u001B[39;00m\n\u001B[0;32m---> 19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgensim\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m utils, matutils\n\u001B[1;32m     22\u001B[0m logger \u001B[38;5;241m=\u001B[39m logging\u001B[38;5;241m.\u001B[39mgetLogger(\u001B[38;5;18m__name__\u001B[39m)\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mCorpusABC\u001B[39;00m(utils\u001B[38;5;241m.\u001B[39mSaveLoad):\n",
      "File \u001B[0;32m~/Documents/IASD/NLP/Les Ateliers/Atelier_3/NLP_LAB_3/.venv/lib/python3.11/site-packages/gensim/matutils.py:20\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msparse\u001B[39;00m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mstats\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m entropy\n\u001B[0;32m---> 20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlinalg\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_blas_funcs, triu\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlinalg\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlapack\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_lapack_funcs\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mspecial\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m psi  \u001B[38;5;66;03m# gamma function utils\u001B[39;00m\n",
      "\u001B[0;31mImportError\u001B[0m: cannot import name 'triu' from 'scipy.linalg' (/Users/marouandgh/Documents/IASD/NLP/Les Ateliers/Atelier_3/NLP_LAB_3/.venv/lib/python3.11/site-packages/scipy/linalg/__init__.py)"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Train Word2Vec models (CBOW and Skip-gram)\n",
    "cbow_model = Word2Vec(sentences=dataset['tokens'], vector_size=100, window=5, min_count=1, sg=0)\n",
    "skipgram_model = Word2Vec(sentences=dataset['tokens'], vector_size=100, window=5, min_count=1, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db94831-41a2-4fdb-aa15-8c22e568151d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-20T01:46:37.930752Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_sentence_embedding(sentence, model):\n",
    "    # Get vectors for words in the sentence, ignore words not in the model's vocabulary\n",
    "    word_vectors = [model.wv[word] for word in sentence if word in model.wv]\n",
    "    if not word_vectors:  # If no words in the sentence are in the vocabulary, return a zero vector\n",
    "        return np.zeros(model.vector_size)\n",
    "    # Compute the mean of the word vectors\n",
    "    return np.mean(word_vectors, axis=0)\n",
    "\n",
    "\n",
    "cbow_vectors = np.array([get_sentence_embedding(sentence, cbow_model) for sentence in dataset['tokens']])\n",
    "skipgram_vectors = np.array([get_sentence_embedding(sentence, skipgram_model) for sentence in dataset['tokens']])\n",
    "\n",
    "\n",
    "print(len(cbow_vectors))\n",
    "print(len(skipgram_vectors))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623f4cfa-5d92-4d50-a781-7d84e8ef5293",
   "metadata": {},
   "source": [
    "# BagOfWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c540978-2730-4021-aec0-af416cdc6d17",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-20T01:46:37.933389Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the text data\n",
    "bow_matrix = vectorizer.fit_transform(dataset['tokens'].apply(lambda x: ' '.join(x)))\n",
    "bow_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c5918c-823c-4017-ab11-d4bd4c7f6835",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3302192d-64aa-4720-a081-56a29321c3f0",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-20T01:46:37.935253Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the text data\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(dataset['tokens'].apply(lambda x: ' '.join(x)))\n",
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25d5eda-64cc-47e8-a95d-728a0652b07e",
   "metadata": {},
   "source": [
    "# Models training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7269564b-f0f2-401c-831f-b116a1bbbc1f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-20T01:46:37.937360Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce01519c-c966-4b3e-ba34-bb4bc8c9062d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-20T01:46:37.939885Z"
    }
   },
   "outputs": [],
   "source": [
    "X , y = np.array(cbow_vectors), np.array(labels)\n",
    "X = MinMaxScaler(feature_range=(0, 1)).fit_transform(X)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e92134b-2a7c-4fcf-989e-1b827591d706",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-20T01:46:37.943615Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train , X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecd62da-83a6-4cb2-843a-c7d7adbbe390",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-20T01:46:37.947049Z"
    }
   },
   "outputs": [],
   "source": [
    "svc_model = SVC()\n",
    "svc_model.fit(X_train, y_train)\n",
    "svc_prediction = svc_model.predict(X_test)\n",
    "svc_f1 = f1_score(y_test, svc_prediction, average='weighted')\n",
    "svc_accu = accuracy_score(y_test, svc_prediction)\n",
    "print(\"AdaBoost F1 Score:\", svc_f1)\n",
    "print(\"AdaBoost Accuracy:\", svc_accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91be572-66a6-4c49-ab84-449edf6f7c4b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-20T01:46:37.949365Z"
    }
   },
   "outputs": [],
   "source": [
    "adaboost_model = AdaBoostClassifier(n_estimators=200)\n",
    "adaboost_model.fit(X_train, y_train)\n",
    "adaboost_prediction = adaboost_model.predict(X_test)\n",
    "adaboost_f1 = f1_score(y_test, adaboost_prediction, average='weighted')\n",
    "adaboost_accu = accuracy_score(y_test, adaboost_prediction)\n",
    "print(\"AdaBoost F1 Score:\", adaboost_f1)\n",
    "print(\"AdaBoost Accuracy:\", adaboost_accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cef4ed8-1d66-4748-b96b-353f571a0853",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-20T01:46:37.951123Z"
    }
   },
   "outputs": [],
   "source": [
    "# Naive Bayes Model\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "nb_prediction = nb_model.predict(X_test)\n",
    "nb_accu = accuracy_score(y_test, nb_prediction)\n",
    "nb_f1 = f1_score(y_test, nb_prediction, average='weighted')\n",
    "print(\"Naive Bayes Accuracy:\", nb_accu)\n",
    "print(\"Naive Bayes F1 Score:\", nb_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c36b66-4acc-4093-9a58-a02da69a221b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-20T01:46:37.952318Z"
    }
   },
   "outputs": [],
   "source": [
    "# Logistic Regression Model\n",
    "lr_model = LogisticRegression(max_iter=2000)\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_prediction = lr_model.predict(X_test)\n",
    "lr_accu = accuracy_score(y_test, lr_prediction)\n",
    "lr_f1 = f1_score(y_test, lr_prediction, average='weighted')\n",
    "print(\"Logistic Regression Accuracy:\", lr_accu)\n",
    "print(\"Logistic Regression F1 Score:\", lr_f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
