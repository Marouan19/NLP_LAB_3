{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf26d4f0-a929-4918-a557-7f270e827b81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T01:23:18.115308Z",
     "start_time": "2024-05-20T01:23:11.251179Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/marouandgh/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/marouandgh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/marouandgh/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a71c4a6b-9567-44a2-b1d5-ec071399db2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T01:25:19.738970Z",
     "start_time": "2024-05-20T01:25:19.495515Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  sentiment                                      Tweet Content\n0  Positive  im getting on borderlands and i will murder yo...\n1  Positive  I am coming to the borders and I will kill you...\n2  Positive  im getting on borderlands and i will kill you ...\n3  Positive  im coming on borderlands and i will murder you...\n4  Positive  im getting on borderlands 2 and i will murder ...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentiment</th>\n      <th>Tweet Content</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Positive</td>\n      <td>im getting on borderlands and i will murder yo...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Positive</td>\n      <td>I am coming to the borders and I will kill you...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Positive</td>\n      <td>im getting on borderlands and i will kill you ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Positive</td>\n      <td>im coming on borderlands and i will murder you...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Positive</td>\n      <td>im getting on borderlands 2 and i will murder ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"./twitter_training.csv\", names=[\"id\", \"entity\", \"sentiment\", \"Tweet Content\"])\n",
    "dataset = dataset.drop([\"id\", \"entity\"], axis=1)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42089211-71ed-4773-8c94-36f82dfc3fec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T01:25:21.149734Z",
     "start_time": "2024-05-20T01:25:21.121513Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 3 ... 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "labelencoder.fit(dataset[\"sentiment\"])\n",
    "\n",
    "labels = labelencoder.transform(dataset[\"sentiment\"])\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968962dc-75af-4da6-8bf0-a7aebcb966cb",
   "metadata": {},
   "source": [
    "# 1. NLP Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a921a28b-2469-4e16-9230-9abb6fc16758",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T01:25:34.173819Z",
     "start_time": "2024-05-20T01:25:22.854620Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      sentiment                                      Tweet Content  \\\n0      Positive  im getting on borderlands and i will murder yo...   \n1      Positive  I am coming to the borders and I will kill you...   \n2      Positive  im getting on borderlands and i will kill you ...   \n3      Positive  im coming on borderlands and i will murder you...   \n4      Positive  im getting on borderlands 2 and i will murder ...   \n...         ...                                                ...   \n74677  Positive  Just realized that the Windows partition of my...   \n74678  Positive  Just realized that my Mac window partition is ...   \n74679  Positive  Just realized the windows partition of my Mac ...   \n74680  Positive  Just realized between the windows partition of...   \n74681  Positive  Just like the windows partition of my Mac is l...   \n\n                                                  tokens  \n0      [im, getting, on, borderlands, and, i, will, m...  \n1      [i, am, coming, to, the, borders, and, i, will...  \n2      [im, getting, on, borderlands, and, i, will, k...  \n3      [im, coming, on, borderlands, and, i, will, mu...  \n4      [im, getting, on, borderlands, and, i, will, m...  \n...                                                  ...  \n74677  [just, realized, that, the, windows, partition...  \n74678  [just, realized, that, my, mac, window, partit...  \n74679  [just, realized, the, windows, partition, of, ...  \n74680  [just, realized, between, the, windows, partit...  \n74681  [just, like, the, windows, partition, of, my, ...  \n\n[74682 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentiment</th>\n      <th>Tweet Content</th>\n      <th>tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Positive</td>\n      <td>im getting on borderlands and i will murder yo...</td>\n      <td>[im, getting, on, borderlands, and, i, will, m...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Positive</td>\n      <td>I am coming to the borders and I will kill you...</td>\n      <td>[i, am, coming, to, the, borders, and, i, will...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Positive</td>\n      <td>im getting on borderlands and i will kill you ...</td>\n      <td>[im, getting, on, borderlands, and, i, will, k...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Positive</td>\n      <td>im coming on borderlands and i will murder you...</td>\n      <td>[im, coming, on, borderlands, and, i, will, mu...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Positive</td>\n      <td>im getting on borderlands 2 and i will murder ...</td>\n      <td>[im, getting, on, borderlands, and, i, will, m...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>74677</th>\n      <td>Positive</td>\n      <td>Just realized that the Windows partition of my...</td>\n      <td>[just, realized, that, the, windows, partition...</td>\n    </tr>\n    <tr>\n      <th>74678</th>\n      <td>Positive</td>\n      <td>Just realized that my Mac window partition is ...</td>\n      <td>[just, realized, that, my, mac, window, partit...</td>\n    </tr>\n    <tr>\n      <th>74679</th>\n      <td>Positive</td>\n      <td>Just realized the windows partition of my Mac ...</td>\n      <td>[just, realized, the, windows, partition, of, ...</td>\n    </tr>\n    <tr>\n      <th>74680</th>\n      <td>Positive</td>\n      <td>Just realized between the windows partition of...</td>\n      <td>[just, realized, between, the, windows, partit...</td>\n    </tr>\n    <tr>\n      <th>74681</th>\n      <td>Positive</td>\n      <td>Just like the windows partition of my Mac is l...</td>\n      <td>[just, like, the, windows, partition, of, my, ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>74682 rows Ã— 3 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_tweet(text):\n",
    "    if not isinstance(text, str):\n",
    "        return ''\n",
    "    # Apply regular expression to replace non-alphabetical characters with a space\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    return cleaned_text\n",
    "\n",
    "# text Cleanign \n",
    "dataset[\"tokens\"] = dataset[\"Tweet Content\"].apply(lambda x: word_tokenize(clean_tweet(x).lower()))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f18b5946-82f4-40cd-ae2c-bea040871ee9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T01:25:34.806439Z",
     "start_time": "2024-05-20T01:25:34.175221Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      sentiment                                      Tweet Content  \\\n0      Positive  im getting on borderlands and i will murder yo...   \n1      Positive  I am coming to the borders and I will kill you...   \n2      Positive  im getting on borderlands and i will kill you ...   \n3      Positive  im coming on borderlands and i will murder you...   \n4      Positive  im getting on borderlands 2 and i will murder ...   \n...         ...                                                ...   \n74677  Positive  Just realized that the Windows partition of my...   \n74678  Positive  Just realized that my Mac window partition is ...   \n74679  Positive  Just realized the windows partition of my Mac ...   \n74680  Positive  Just realized between the windows partition of...   \n74681  Positive  Just like the windows partition of my Mac is l...   \n\n                                                  tokens  \n0                     [im, getting, borderlands, murder]  \n1                                [coming, borders, kill]  \n2                       [im, getting, borderlands, kill]  \n3                      [im, coming, borderlands, murder]  \n4                     [im, getting, borderlands, murder]  \n...                                                  ...  \n74677  [realized, windows, partition, mac, like, year...  \n74678  [realized, mac, window, partition, years, behi...  \n74679  [realized, windows, partition, mac, years, beh...  \n74680  [realized, windows, partition, mac, like, year...  \n74681  [like, windows, partition, mac, like, years, b...  \n\n[74682 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentiment</th>\n      <th>Tweet Content</th>\n      <th>tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Positive</td>\n      <td>im getting on borderlands and i will murder yo...</td>\n      <td>[im, getting, borderlands, murder]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Positive</td>\n      <td>I am coming to the borders and I will kill you...</td>\n      <td>[coming, borders, kill]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Positive</td>\n      <td>im getting on borderlands and i will kill you ...</td>\n      <td>[im, getting, borderlands, kill]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Positive</td>\n      <td>im coming on borderlands and i will murder you...</td>\n      <td>[im, coming, borderlands, murder]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Positive</td>\n      <td>im getting on borderlands 2 and i will murder ...</td>\n      <td>[im, getting, borderlands, murder]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>74677</th>\n      <td>Positive</td>\n      <td>Just realized that the Windows partition of my...</td>\n      <td>[realized, windows, partition, mac, like, year...</td>\n    </tr>\n    <tr>\n      <th>74678</th>\n      <td>Positive</td>\n      <td>Just realized that my Mac window partition is ...</td>\n      <td>[realized, mac, window, partition, years, behi...</td>\n    </tr>\n    <tr>\n      <th>74679</th>\n      <td>Positive</td>\n      <td>Just realized the windows partition of my Mac ...</td>\n      <td>[realized, windows, partition, mac, years, beh...</td>\n    </tr>\n    <tr>\n      <th>74680</th>\n      <td>Positive</td>\n      <td>Just realized between the windows partition of...</td>\n      <td>[realized, windows, partition, mac, like, year...</td>\n    </tr>\n    <tr>\n      <th>74681</th>\n      <td>Positive</td>\n      <td>Just like the windows partition of my Mac is l...</td>\n      <td>[like, windows, partition, mac, like, years, b...</td>\n    </tr>\n  </tbody>\n</table>\n<p>74682 rows Ã— 3 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Removing StopWords\n",
    "dataset[\"tokens\"] = dataset[\"tokens\"].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce1c8cb7-bb58-45ce-a0ac-e56c7ab6ce76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T01:25:42.006870Z",
     "start_time": "2024-05-20T01:25:34.807907Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      sentiment                                      Tweet Content  \\\n0      Positive  im getting on borderlands and i will murder yo...   \n1      Positive  I am coming to the borders and I will kill you...   \n2      Positive  im getting on borderlands and i will kill you ...   \n3      Positive  im coming on borderlands and i will murder you...   \n4      Positive  im getting on borderlands 2 and i will murder ...   \n...         ...                                                ...   \n74677  Positive  Just realized that the Windows partition of my...   \n74678  Positive  Just realized that my Mac window partition is ...   \n74679  Positive  Just realized the windows partition of my Mac ...   \n74680  Positive  Just realized between the windows partition of...   \n74681  Positive  Just like the windows partition of my Mac is l...   \n\n                                                  tokens  \n0                      [im, getting, borderland, murder]  \n1                                 [coming, border, kill]  \n2                        [im, getting, borderland, kill]  \n3                       [im, coming, borderland, murder]  \n4                      [im, getting, borderland, murder]  \n...                                                  ...  \n74677  [realized, window, partition, mac, like, year,...  \n74678  [realized, mac, window, partition, year, behin...  \n74679  [realized, window, partition, mac, year, behin...  \n74680  [realized, window, partition, mac, like, year,...  \n74681  [like, window, partition, mac, like, year, beh...  \n\n[74682 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentiment</th>\n      <th>Tweet Content</th>\n      <th>tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Positive</td>\n      <td>im getting on borderlands and i will murder yo...</td>\n      <td>[im, getting, borderland, murder]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Positive</td>\n      <td>I am coming to the borders and I will kill you...</td>\n      <td>[coming, border, kill]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Positive</td>\n      <td>im getting on borderlands and i will kill you ...</td>\n      <td>[im, getting, borderland, kill]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Positive</td>\n      <td>im coming on borderlands and i will murder you...</td>\n      <td>[im, coming, borderland, murder]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Positive</td>\n      <td>im getting on borderlands 2 and i will murder ...</td>\n      <td>[im, getting, borderland, murder]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>74677</th>\n      <td>Positive</td>\n      <td>Just realized that the Windows partition of my...</td>\n      <td>[realized, window, partition, mac, like, year,...</td>\n    </tr>\n    <tr>\n      <th>74678</th>\n      <td>Positive</td>\n      <td>Just realized that my Mac window partition is ...</td>\n      <td>[realized, mac, window, partition, year, behin...</td>\n    </tr>\n    <tr>\n      <th>74679</th>\n      <td>Positive</td>\n      <td>Just realized the windows partition of my Mac ...</td>\n      <td>[realized, window, partition, mac, year, behin...</td>\n    </tr>\n    <tr>\n      <th>74680</th>\n      <td>Positive</td>\n      <td>Just realized between the windows partition of...</td>\n      <td>[realized, window, partition, mac, like, year,...</td>\n    </tr>\n    <tr>\n      <th>74681</th>\n      <td>Positive</td>\n      <td>Just like the windows partition of my Mac is l...</td>\n      <td>[like, window, partition, mac, like, year, beh...</td>\n    </tr>\n  </tbody>\n</table>\n<p>74682 rows Ã— 3 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "dataset[\"tokens\"] = dataset[\"tokens\"].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4561e10b-04ad-42af-b36c-5aec3fdc09e1",
   "metadata": {},
   "source": [
    "# Word2Vec (CBOW and Skip-gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e972bd-a1ce-4089-964c-e57fb3357521",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Train Word2Vec models (CBOW and Skip-gram)\n",
    "cbow_model = Word2Vec(sentences=dataset['tokens'], vector_size=100, window=5, min_count=1, sg=0)\n",
    "skipgram_model = Word2Vec(sentences=dataset['tokens'], vector_size=100, window=5, min_count=1, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db94831-41a2-4fdb-aa15-8c22e568151d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-20T01:25:43.327440Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_sentence_embedding(sentence, model):\n",
    "    # Get vectors for words in the sentence, ignore words not in the model's vocabulary\n",
    "    word_vectors = [model.wv[word] for word in sentence if word in model.wv]\n",
    "    if not word_vectors:  # If no words in the sentence are in the vocabulary, return a zero vector\n",
    "        return np.zeros(model.vector_size)\n",
    "    # Compute the mean of the word vectors\n",
    "    return np.mean(word_vectors, axis=0)\n",
    "\n",
    "\n",
    "cbow_vectors = np.array([get_sentence_embedding(sentence, cbow_model) for sentence in dataset['tokens']])\n",
    "skipgram_vectors = np.array([get_sentence_embedding(sentence, skipgram_model) for sentence in dataset['tokens']])\n",
    "\n",
    "\n",
    "print(len(cbow_vectors))\n",
    "print(len(skipgram_vectors))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623f4cfa-5d92-4d50-a781-7d84e8ef5293",
   "metadata": {},
   "source": [
    "# BagOfWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c540978-2730-4021-aec0-af416cdc6d17",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-20T01:25:43.333474Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the text data\n",
    "bow_matrix = vectorizer.fit_transform(dataset['tokens'].apply(lambda x: ' '.join(x)))\n",
    "bow_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c5918c-823c-4017-ab11-d4bd4c7f6835",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3302192d-64aa-4720-a081-56a29321c3f0",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-20T01:25:43.338959Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the text data\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(dataset['tokens'].apply(lambda x: ' '.join(x)))\n",
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25d5eda-64cc-47e8-a95d-728a0652b07e",
   "metadata": {},
   "source": [
    "# Models training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7269564b-f0f2-401c-831f-b116a1bbbc1f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-20T01:25:43.346014Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce01519c-c966-4b3e-ba34-bb4bc8c9062d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-20T01:25:43.350574Z"
    }
   },
   "outputs": [],
   "source": [
    "X , y = np.array(cbow_vectors), np.array(labels)\n",
    "X = MinMaxScaler(feature_range=(0, 1)).fit_transform(X)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e92134b-2a7c-4fcf-989e-1b827591d706",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-20T01:25:43.354960Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train , X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecd62da-83a6-4cb2-843a-c7d7adbbe390",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-20T01:25:43.359173Z"
    }
   },
   "outputs": [],
   "source": [
    "svc_model = SVC()\n",
    "svc_model.fit(X_train, y_train)\n",
    "svc_prediction = svc_model.predict(X_test)\n",
    "svc_f1 = f1_score(y_test, svc_prediction, average='weighted')\n",
    "svc_accu = accuracy_score(y_test, svc_prediction)\n",
    "print(\"AdaBoost F1 Score:\", svc_f1)\n",
    "print(\"AdaBoost Accuracy:\", svc_accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91be572-66a6-4c49-ab84-449edf6f7c4b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-20T01:25:43.363691Z"
    }
   },
   "outputs": [],
   "source": [
    "adaboost_model = AdaBoostClassifier(n_estimators=200)\n",
    "adaboost_model.fit(X_train, y_train)\n",
    "adaboost_prediction = adaboost_model.predict(X_test)\n",
    "adaboost_f1 = f1_score(y_test, adaboost_prediction, average='weighted')\n",
    "adaboost_accu = accuracy_score(y_test, adaboost_prediction)\n",
    "print(\"AdaBoost F1 Score:\", adaboost_f1)\n",
    "print(\"AdaBoost Accuracy:\", adaboost_accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cef4ed8-1d66-4748-b96b-353f571a0853",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-20T01:25:43.367932Z"
    }
   },
   "outputs": [],
   "source": [
    "# Naive Bayes Model\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "nb_prediction = nb_model.predict(X_test)\n",
    "nb_accu = accuracy_score(y_test, nb_prediction)\n",
    "nb_f1 = f1_score(y_test, nb_prediction, average='weighted')\n",
    "print(\"Naive Bayes Accuracy:\", nb_accu)\n",
    "print(\"Naive Bayes F1 Score:\", nb_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c36b66-4acc-4093-9a58-a02da69a221b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-20T01:25:43.373087Z"
    }
   },
   "outputs": [],
   "source": [
    "# Logistic Regression Model\n",
    "lr_model = LogisticRegression(max_iter=2000)\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_prediction = lr_model.predict(X_test)\n",
    "lr_accu = accuracy_score(y_test, lr_prediction)\n",
    "lr_f1 = f1_score(y_test, lr_prediction, average='weighted')\n",
    "print(\"Logistic Regression Accuracy:\", lr_accu)\n",
    "print(\"Logistic Regression F1 Score:\", lr_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa8a825-a158-471c-889f-4b4864a69740",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-20T01:25:43.376669Z"
    }
   },
   "outputs": [],
   "source": [
    "X[X < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82601030-a486-4242-bc1c-274f07b2bcef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
