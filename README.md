# Language Modeling Regression

## Overview
- **Problem Definition**: This project focuses on building a language model that can predict the next word in a sequence using regression.
- **Dataset**: The notebook uses a preprocessed text dataset that contains a collection of text samples.
- **Approach**: The notebook explores different regression techniques, such as linear regression and polynomial regression, to build the language model.

## Requirements
- Python 3.x
- Jupyter Notebook
- NumPy
- Pandas
- Scikit-learn
- Matplotlib

## Usage
1. Clone the repository:
```bash
git clone https://github.com/Marouan19/NLP_LAB_3.git
```
2. Navigate to the project directory:
```bash
cd NLP_LAB_3
```
3. Open the Jupyter Notebook:
```bash
jupyter notebook Language_Modeling_Regression.ipynb
```
4. Run the notebook cells to execute the code and explore the results.

## Content
The notebook is structured as follows:

1. **Data Preprocessing**: This section covers the preprocessing of the text data, including tokenization, vocabulary creation, and encoding.
2. **Feature Engineering**: This section discusses the feature engineering process, where the text data is transformed into a format suitable for regression modeling.
3. **Model Training**: This section covers the implementation of various regression techniques, such as linear regression and polynomial regression, to build the language model.
4. **Model Evaluation**: This section evaluates the performance of the trained models using appropriate metrics.
5. **Results and Discussion**: This section presents the results of the language modeling task and discusses the insights gained from the analysis.



# Language Modeling and Classification

This project focuses on performing language modeling and classification tasks using Python.

## Data

The project utilizes the following CSV files:

1. `twitter_validation.csv`: Contains Twitter data with columns for `id`, `label`, and `text`.
2. `twitter_training.csv`: Contains Twitter data with columns for `id`, `label`, and `text`.

## Notebooks

The project includes the following Jupyter Notebook:

1. `Language_Modeling_Classification.ipynb`: This notebook contains the code for preprocessing the data, training language models, and performing classification tasks.

## Dependencies

The project requires the following Python libraries:

- `pandas`
- `numpy`
- `nltk` (Natural Language Toolkit)
- `sklearn` (scikit-learn)

These dependencies can be installed using `pip` or a package manager like `conda`.

## Usage

1. Clone the repository to your local machine.
2. Open the `Language_Modeling_Classification.ipynb` notebook and run the cells to execute the code.
3. Adjust the code as needed to experiment with different preprocessing techniques, models, or classification tasks.
